YELP DATASET EXPLORATION

Reviews: 6,990,280 (6990280)
Columns: Index(['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date'], dtype='object')
Sample column: 
	review_id                                 KU_O5udG6zpxOg-VcAEodg
	user_id                                   mh_-eMZ6K5RLWhZyISBhwA
	business_id                               XQfwVwDr-v0ZS3_CbbE5Xw
	stars                                                          3
	useful                                                         0
	funny                                                          0
	cool                                                           0
	text           If you decide to eat here, just be aware it is...
	date                                         2018-07-07 22:09:11
	Name: 0, dtype: object
	
Review counter: 
   stars     size
0      1  1069561
1      2   544240
2      3   691934
3      4  1452918
4      5  3231627


df.groupby(df.date.dt.year)['stars'].sum()
Review by year
2005       3331
2006      15393
2007      59369
2008     183204
2009     276679
2010     515748
2011     855077
2012    1054246
2013    1414335
2014    1944411
2015    2576034
2016    2857598
2017    3098620
2018    3427031
2019    3417355
2020    2097690
2021    2290226
2022     117303

                 useful     funny      cool  review_length
useful         1.000000  0.768755 -0.729256       0.799799
funny          0.768755  1.000000 -0.485747       0.960635
cool          -0.729256 -0.485747  1.000000      -0.695158
review_length  0.799799  0.960635 -0.695158       1.000000

NAIVE BAYES: 
	Training Set
	Accuracy:  0.567703 

				  precision    recall  f1-score   support

			   1     0.6092    0.7014    0.6520    400000
			   2     0.4933    0.4445    0.4676    400000
			   3     0.4996    0.4897    0.4946    400000
			   4     0.5214    0.6173    0.5653    400000
			   5     0.7475    0.5856    0.6567    400000

		accuracy                         0.5677   2000000
	   macro avg     0.5742    0.5677    0.5673   2000000
	weighted avg     0.5742    0.5677    0.5673   2000000


Testing Set
Accuracy:  0.556568 

			  precision    recall  f1-score   support

		   1     0.6027    0.6902    0.6435     76303
		   2     0.3072    0.4074    0.3503     38783
		   3     0.3512    0.4451    0.3926     49443
		   4     0.3982    0.5767    0.4711    104155
		   5     0.8651    0.5523    0.6741    231316

	accuracy                         0.5566    500000
   macro avg     0.5049    0.5343    0.5063    500000
weighted avg     0.6337    0.5566    0.5742    500000

LOGISTIC REGRESSION =============================================
	Training Set
	Accuracy:  0.6088825 

				  precision    recall  f1-score   support

			   1     0.7218    0.7521    0.7366    400000
			   2     0.5327    0.5476    0.5400    400000
			   3     0.5325    0.4709    0.4998    400000
			   4     0.5458    0.5358    0.5408    400000
			   5     0.6936    0.7381    0.7152    400000

		accuracy                         0.6089   2000000
	   macro avg     0.6053    0.6089    0.6065   2000000
	weighted avg     0.6053    0.6089    0.6065   2000000

	<Figure size 432x288 with 0 Axes>
	<Figure size 432x288 with 0 Axes>

	evaluate_model(classifier_lr, X_test, y_test, label="Testing", model_name="logistic regression testing")
	Testing Set
	Accuracy:  0.650252 

				  precision    recall  f1-score   support

			   1     0.7860    0.7471    0.7661     76303
			   2     0.3803    0.5403    0.4464     38783
			   3     0.3998    0.4593    0.4275     49443
			   4     0.4753    0.5279    0.5002    104155
			   5     0.8479    0.7326    0.7860    231316

		accuracy                         0.6503    500000
	   macro avg     0.5778    0.6014    0.5852    500000
	weighted avg     0.6802    0.6503    0.6617    500000

RANDOM FOREST =============================================

	Training Set
	Accuracy:  0.6016465 

				  precision    recall  f1-score   support

			   1     0.6033    0.8275    0.6978    400000
			   2     0.5916    0.4494    0.5108    400000
			   3     0.5996    0.4737    0.5293    400000
			   4     0.5744    0.5129    0.5419    400000
			   5     0.6280    0.7448    0.6814    400000

		accuracy                         0.6016   2000000
	   macro avg     0.5994    0.6016    0.5922   2000000
	weighted avg     0.5994    0.6016    0.5922   2000000

	Testing Set
	Accuracy:  0.615466 

				  precision    recall  f1-score   support

			   1     0.6197    0.8061    0.7007     76303
			   2     0.3630    0.3822    0.3724     38783
			   3     0.3815    0.3989    0.3900     49443
			   4     0.4536    0.4472    0.4504    104155
			   5     0.8032    0.7138    0.7559    231316

		accuracy                         0.6155    500000
	   macro avg     0.5242    0.5496    0.5339    500000
	weighted avg     0.6266    0.6155    0.6179    500000























